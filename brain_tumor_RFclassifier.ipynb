{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee1cb8cc-b9fa-44ef-9611-1c3dbeb1b6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "340b57c2-41f5-4d4c-ac2b-532cde0c40db",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_loc = 'dataset'\n",
    "IMG_SIZE = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d78fb3c-9a13-400c-ac23-a35fed266961",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['glioma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cbdf389-3d41-4c82-a436-59e5a199112a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = []\n",
    "training_path = os.path.join(dataset_loc, 'Training') \n",
    "\n",
    "for category in categories:\n",
    "    cancer_path = os.path.join(training_path, category)\n",
    "    category_idx = categories.index(category)\n",
    "    for img_file in os.listdir(cancer_path):\n",
    "        try:\n",
    "            img_array = cv2.imread(os.path.join(cancer_path, img_file), cv2.IMREAD_GRAYSCALE) # convert image to gray scale\n",
    "            img_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE)) # all images same size\n",
    "            img_array = tf.keras.utils.normalize(img_array)\n",
    "\n",
    "            training_data.append([img_array, category_idx])\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0945eafa-9e4b-4a74-a1ee-528e4bb116f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = []\n",
    "validation_path = os.path.join(dataset_loc, 'Testing') \n",
    "\n",
    "for category in categories:\n",
    "    cancer_path = os.path.join(validation_path, category)\n",
    "    category_idx = categories.index(category)\n",
    "    for img_file in os.listdir(cancer_path):\n",
    "        try:\n",
    "            img_array = cv2.imread(os.path.join(cancer_path, img_file), cv2.IMREAD_GRAYSCALE) # convert image to gray scale\n",
    "            img_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE)) # all images same size\n",
    "            img_array = tf.keras.utils.normalize(img_array)\n",
    "            \n",
    "            validation_data.append([img_array, category_idx])\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ea3d407-1aa4-4a76-bb4f-61ed29eac8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(training_data)\n",
    "random.shuffle(validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8057c096-c2ee-4934-aa2c-297e980c8b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [pair[0] for pair in training_data]\n",
    "y_train = [pair[1] for pair in training_data]\n",
    "\n",
    "X_validation = [pair[0] for pair in validation_data]\n",
    "y_validation = [pair[1] for pair in validation_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75a447bc-76d6-4371-8a33-8a9307f35347",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train) # training and validation sets must be converted to np_arrays for cnn model\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "X_validation = np.array(X_validation)\n",
    "y_validation = np.array(y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "560abd9e-a46c-4701-9198-d130593f2c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "X_validation = X_validation.reshape(X_validation.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e44c84c-191e-4009-ba28-dd67fc91c47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2870, 62500)\n",
      "(2870,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X_train))\n",
    "print(np.shape(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "313a3420-12c3-4b0a-bda2-e34b966df906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=200)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=200)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_estimators=200)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Keras model\n",
    "model = RandomForestClassifier(n_estimators=200)\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "344164bf-c9a2-43ce-864e-37bd6a3df646",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.score(X_validation, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb730406-8463-4f2d-920a-7eab5a57f1ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.682741116751269\n"
     ]
    }
   ],
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff82587a-11b2-4b3a-838f-9a15567de9d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2c9ad2-3304-45a5-a6cd-82bc9a1b1713",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
